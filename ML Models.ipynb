{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from numpy import absolute\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "import math\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import urllib.request\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "adult_df = pd.read_csv('adult.data')\n",
        "adult_df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "                    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "                    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
        "adult_df['income'] = adult_df['income'].apply(lambda x: 1 if x == ' >50K' else 0)\n",
        "adult_df = adult_df.replace('?', np.nan)\n",
        "adult_df = adult_df.dropna()\n",
        "adult_df = adult_df[~adult_df.isin(['?'])]\n",
        "adult_df = adult_df.dropna(axis=1)\n",
        "adult_df.head()\n",
        "categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship',\n",
        "                    'race', 'sex', 'native-country']\n",
        "adult_df = pd.get_dummies(adult_df, columns=categorical_cols)\n",
        "X_train, X_test, y_train, y_test = train_test_split(adult_df.drop('income', axis=1),\n",
        "                                                    adult_df['income'],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "# LOG\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "logreg = LogisticRegression()\n",
        "params = {'C': np.logspace(-3, 3, 7)}\n",
        "gs_logreg = GridSearchCV(logreg, params, cv=kf, scoring='accuracy')\n",
        "gs_logreg.fit(X_train, y_train)\n",
        "logreg_best = gs_logreg.best_estimator_\n",
        "y_predLog = logreg_best.predict(X_test)\n",
        "# Mathews\n",
        "mathews_Logistic = metrics.matthews_corrcoef(y_test, y_predLog)\n",
        "# RIDG:\n",
        "ridge = Ridge()\n",
        "params = {'alpha': np.logspace(-3, 3, 7)}\n",
        "gs_ridge = GridSearchCV(ridge, params, cv=kf, scoring='roc_auc')\n",
        "gs_ridge.fit(X_train, y_train)\n",
        "ridge_best = gs_ridge.best_estimator_\n",
        "# AUC\n",
        "y_pred = ridge_best.predict(X_test)\n",
        "auc_Ridge = roc_auc_score(y_test, y_pred)\n",
        "# Lasso Regression\n",
        "X_test = X_test[X_train.columns]\n",
        "lasso = Lasso()\n",
        "params = {'alpha': np.logspace(-3, 3, 7)}\n",
        "gs_lasso = GridSearchCV(lasso, params, cv=kf, scoring='roc_auc')\n",
        "gs_lasso.fit(X_train, y_train)\n",
        "lasso_best = gs_lasso.best_estimator_\n",
        "lasso_best.fit(X_train, y_train)\n",
        "# AUC\n",
        "y_pred_prob = lasso_best.predict(X_test)\n",
        "auc_Lasso = roc_auc_score(y_test, y_pred_prob)\n",
        "print('MathewsCoeff Logistc Regression:', mathews_Logistic)\n",
        "print('AUC Score Ridge Regression:', auc_Ridge)\n",
        "print('AUC Score Lasso Regression:', auc_Lasso)\n",
        "print('Best Ridge hyperpars:', gs_ridge.best_params_)\n",
        "print('Best Ridge AUC on training:', gs_ridge.best_score_)\n",
        "print('Best Logistic hyperpars:', gs_logreg.best_params_)\n",
        "print('Best Logistic AUC Score on training:', gs_logreg.best_score_)\n",
        "print('Best Lasso hyperparams:', gs_lasso.best_params_)\n",
        "print('Best Lasso AUC on training:', gs_lasso.best_score_)\n",
        "print(\"Here is a hard coded copy of the values I got:\\\n",
        "\\MathewsCoeff Logistc Regression: 0.36209708603506596\\\n",
        "AUC Score Ridge Regression: 0.8914701241856677\\\n",
        "AUC Score Lasso Regression: 0.8910326750814332\\\n",
        "Best Ridge hyperpars: {'alpha': 100.0}\\\n",
        "Best Ridge AUC on training: 0.8938553063525679\\\n",
        "Best Logistic hyperpars: {'C': 0.001}\\\n",
        "Best Logistic AUC Score on training: 0.7994089809863263\\\n",
        "Best Lasso hyperparams: {'alpha': 0.001}\\\n",
        "Best Lasso AUC on training: 0.8931061050928213\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hqs3j36SYSrI",
        "outputId": "1f8c417c-2667-4808-fbf3-a407e9a8687f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.69118e-18): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.64503e-18): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.63351e-18): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.66624e-18): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.67956e-18): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.6912e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.64502e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.63349e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.66626e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.67961e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MathewsCoeff Logistc Regression: 0.36209708603506596\n",
            "AUC Score Ridge Regression: 0.8914701241856677\n",
            "AUC Score Lasso Regression: 0.8910326750814332\n",
            "Best Ridge hyperpars: {'alpha': 100.0}\n",
            "Best Ridge AUC on training: 0.8938553063525679\n",
            "Best Logistic hyperpars: {'C': 0.001}\n",
            "Best Logistic AUC Score on training: 0.7994089809863263\n",
            "Best Lasso hyperparams: {'alpha': 0.001}\n",
            "Best Lasso AUC on training: 0.8931061050928213\n",
            "Here is a hard coded copy of the values I got:\\MathewsCoeff Logistc Regression: 0.36209708603506596AUC Score Ridge Regression: 0.8914701241856677AUC Score Lasso Regression: 0.8910326750814332Best Ridge hyperpars: {'alpha': 100.0}Best Ridge AUC on training: 0.8938553063525679Best Logistic hyperpars: {'C': 0.001}Best Logistic AUC Score on training: 0.7994089809863263Best Lasso hyperparams: {'alpha': 0.001}Best Lasso AUC on training: 0.8931061050928213\n"
          ]
        }
      ]
    }
  ]
}